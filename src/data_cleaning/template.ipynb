{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for the experiment\n",
    "\n",
    "## Use this as training data\n",
    "ds = load_dataset(\"StephanAkkerman/financial-tweets-crypto\")\n",
    "df = pd.DataFrame(ds['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_y/n_rzm4fs471481_r0lswqbrm0000gn/T/ipykernel_36031/3929333518.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'] = df['sentiment'].str.split().str[0]\n"
     ]
    }
   ],
   "source": [
    "# Removing invalid data\n",
    "\n",
    "# Drop rows with missing sentiment\n",
    "df = df[~df['sentiment'].isna()]\n",
    "\n",
    "# merge the sentiments to either Neutral, Bullish, Bearish only\n",
    "df['sentiment'] = df['sentiment'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df['sentiment'].isnull().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sentiment values: ['Bullish' 'Neutral' 'Bearish']\n"
     ]
    }
   ],
   "source": [
    "# Make sure the sentiment values are valid\n",
    "# Define expected sentiment values\n",
    "valid_sentiments = ['Neutral', 'Bullish', 'Bearish']\n",
    "\n",
    "# Assert that all sentiments are valid\n",
    "assert df['sentiment'].isin(valid_sentiments).all(), \"Found unexpected sentiment values\"\n",
    "\n",
    "# Verify unique values (optional)\n",
    "print(\"Unique sentiment values:\", df['sentiment'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If using pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (38953, 13)\n",
      "Testing set shape: (9739, 13)\n"
     ]
    }
   ],
   "source": [
    "# Create indices for train-test split\n",
    "indices = np.arange(len(df))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test dataframes\n",
    "df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_test = df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# Verify the split\n",
    "print(f\"Training set shape: {df_train.shape}\")\n",
    "print(f\"Testing set shape: {df_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If using huggingfacedataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Dataset Dictionary:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image_url', 'proxy_image_url', 'image_dimensions', 'thumbnail_url', 'proxy_thumbnail_url', 'thumbnail_dimensions', 'timestamp', 'description', 'url', 'embed_title', 'tweet_type', 'financial_info', 'sentiment'],\n",
      "        num_rows: 38953\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image_url', 'proxy_image_url', 'image_dimensions', 'thumbnail_url', 'proxy_thumbnail_url', 'thumbnail_dimensions', 'timestamp', 'description', 'url', 'embed_title', 'tweet_type', 'financial_info', 'sentiment'],\n",
      "        num_rows: 9739\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrames to HuggingFace Datasets\n",
    "hf_train = Dataset.from_pandas(df_train)\n",
    "hf_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "# Optional: Create a DatasetDict for easier handling\n",
    "from datasets import DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': hf_train,\n",
    "    'test': hf_test\n",
    "})\n",
    "\n",
    "# Verify the complete dataset\n",
    "print(\"\\nComplete Dataset Dictionary:\")\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffffd4; padding: 10px; border-radius: 5px;\">\n",
    "<strong>⚠️ Important:</strong> All experiments should use the above df_train and df_test generated from the code above!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
